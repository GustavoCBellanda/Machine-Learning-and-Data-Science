{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 98,8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./Machine Learning e Data Science com Python de A Ã  Z/Bases de dados/credit.pkl', 'rb') as f:\n",
    "    x_credit_treinamento, y_credit_treinamento, x_credit_teste, y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 3), (1500,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit_treinamento.shape, y_credit_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 3), (500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit_teste.shape, y_credit_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0, random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_credit = SVC(kernel='rbf', random_state=1, C=2.0)\n",
    "svm_credit.fit(x_credit_treinamento, y_credit_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes = svm_credit.predict(x_credit_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_credit_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy_score(y_credit_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "cm = ConfusionMatrix(svm_credit)\n",
    "cm.fit(x_credit_treinamento, y_credit_treinamento)\n",
    "cm.score(x_credit_teste, y_credit_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       436\n",
      "           1       0.97      0.94      0.95        64\n",
      "\n",
      "    accuracy                           0.99       500\n",
      "   macro avg       0.98      0.97      0.97       500\n",
      "weighted avg       0.99      0.99      0.99       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_credit_teste, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Support Vector Classification.\n",
      "\n",
      "    The implementation is based on libsvm. The fit time scales at least\n",
      "    quadratically with the number of samples and may be impractical\n",
      "    beyond tens of thousands of samples. For large datasets\n",
      "    consider using :class:`~sklearn.svm.LinearSVC` or\n",
      "    :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      "    :class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
      "\n",
      "    The multiclass support is handled according to a one-vs-one scheme.\n",
      "\n",
      "    For details on the precise mathematical formulation of the provided\n",
      "    kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      "    other, see the corresponding section in the narrative documentation:\n",
      "    :ref:`svm_kernels`.\n",
      "\n",
      "    Read more in the :ref:`User Guide <svm_classification>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    C : float, default=1.0\n",
      "        Regularization parameter. The strength of the regularization is\n",
      "        inversely proportional to C. Must be strictly positive. The penalty\n",
      "        is a squared l2 penalty.\n",
      "\n",
      "    kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      "        Specifies the kernel type to be used in the algorithm.\n",
      "        It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "        a callable.\n",
      "        If none is given, 'rbf' will be used. If a callable is given it is\n",
      "        used to pre-compute the kernel matrix from data matrices; that matrix\n",
      "        should be an array of shape ``(n_samples, n_samples)``.\n",
      "\n",
      "    degree : int, default=3\n",
      "        Degree of the polynomial kernel function ('poly').\n",
      "        Ignored by all other kernels.\n",
      "\n",
      "    gamma : {'scale', 'auto'} or float, default='scale'\n",
      "        Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "\n",
      "        - if ``gamma='scale'`` (default) is passed then it uses\n",
      "          1 / (n_features * X.var()) as value of gamma,\n",
      "        - if 'auto', uses 1 / n_features.\n",
      "\n",
      "        .. versionchanged:: 0.22\n",
      "           The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      "\n",
      "    coef0 : float, default=0.0\n",
      "        Independent term in kernel function.\n",
      "        It is only significant in 'poly' and 'sigmoid'.\n",
      "\n",
      "    shrinking : bool, default=True\n",
      "        Whether to use the shrinking heuristic.\n",
      "        See the :ref:`User Guide <shrinking_svm>`.\n",
      "\n",
      "    probability : bool, default=False\n",
      "        Whether to enable probability estimates. This must be enabled prior\n",
      "        to calling `fit`, will slow down that method as it internally uses\n",
      "        5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      "        `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      "\n",
      "    tol : float, default=1e-3\n",
      "        Tolerance for stopping criterion.\n",
      "\n",
      "    cache_size : float, default=200\n",
      "        Specify the size of the kernel cache (in MB).\n",
      "\n",
      "    class_weight : dict or 'balanced', default=None\n",
      "        Set the parameter C of class i to class_weight[i]*C for\n",
      "        SVC. If not given, all classes are supposed to have\n",
      "        weight one.\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "\n",
      "    verbose : bool, default=False\n",
      "        Enable verbose output. Note that this setting takes advantage of a\n",
      "        per-process runtime setting in libsvm that, if enabled, may not work\n",
      "        properly in a multithreaded context.\n",
      "\n",
      "    max_iter : int, default=-1\n",
      "        Hard limit on iterations within solver, or -1 for no limit.\n",
      "\n",
      "    decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      "        Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      "        (n_samples, n_classes) as all other classifiers, or the original\n",
      "        one-vs-one ('ovo') decision function of libsvm which has shape\n",
      "        (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      "        ('ovo') is always used as multi-class strategy. The parameter is\n",
      "        ignored for binary classification.\n",
      "\n",
      "        .. versionchanged:: 0.19\n",
      "            decision_function_shape is 'ovr' by default.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *decision_function_shape='ovr'* is recommended.\n",
      "\n",
      "        .. versionchanged:: 0.17\n",
      "           Deprecated *decision_function_shape='ovo' and None*.\n",
      "\n",
      "    break_ties : bool, default=False\n",
      "        If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      "        :term:`predict` will break ties according to the confidence values of\n",
      "        :term:`decision_function`; otherwise the first class among the tied\n",
      "        classes is returned. Please note that breaking ties comes at a\n",
      "        relatively high computational cost compared to a simple predict.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the pseudo random number generation for shuffling the data for\n",
      "        probability estimates. Ignored when `probability` is False.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    class_weight_ : ndarray of shape (n_classes,)\n",
      "        Multipliers of parameter C for each class.\n",
      "        Computed based on the ``class_weight`` parameter.\n",
      "\n",
      "    classes_ : ndarray of shape (n_classes,)\n",
      "        The classes labels.\n",
      "\n",
      "    coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      "        Weights assigned to the features (coefficients in the primal\n",
      "        problem). This is only available in the case of a linear kernel.\n",
      "\n",
      "        `coef_` is a readonly property derived from `dual_coef_` and\n",
      "        `support_vectors_`.\n",
      "\n",
      "    dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      "        Dual coefficients of the support vector in the decision\n",
      "        function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      "        their targets.\n",
      "        For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      "        The layout of the coefficients in the multiclass case is somewhat\n",
      "        non-trivial. See the :ref:`multi-class section of the User Guide\n",
      "        <svm_multi_class>` for details.\n",
      "\n",
      "    fit_status_ : int\n",
      "        0 if correctly fitted, 1 otherwise (will raise warning)\n",
      "\n",
      "    intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      "        Constants in decision function.\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    support_ : ndarray of shape (n_SV)\n",
      "        Indices of support vectors.\n",
      "\n",
      "    support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      "        Support vectors.\n",
      "\n",
      "    n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      "        Number of support vectors for each class.\n",
      "\n",
      "    probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      "    probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      "        If `probability=True`, it corresponds to the parameters learned in\n",
      "        Platt scaling to produce probability estimates from decision values.\n",
      "        If `probability=False`, it's an empty array. Platt scaling uses the\n",
      "        logistic function\n",
      "        ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      "        where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      "        more information on the multiclass case and training procedure see\n",
      "        section 8 of [1]_.\n",
      "\n",
      "    shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      "        Array dimensions of training vector ``X``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      "\n",
      "    LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      "        implemented using liblinear. Check the See Also section of\n",
      "        LinearSVC for more comparison element.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      "        <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      "\n",
      "    .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      "        machines and comparison to regularizedlikelihood methods.\"\n",
      "        <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.pipeline import make_pipeline\n",
      "    >>> from sklearn.preprocessing import StandardScaler\n",
      "    >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> from sklearn.svm import SVC\n",
      "    >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      "    >>> clf.fit(X, y)\n",
      "    Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                    ('svc', SVC(gamma='auto'))])\n",
      "\n",
      "    >>> print(clf.predict([[-0.8, -1]]))\n",
      "    [1]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(SVC.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3)\n",
      "(2000, 3)\n",
      "{'C': 1.5, 'kernel': 'rbf', 'tol': 0.001}\n",
      "0.9829999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "x_credit = np.concatenate((x_credit_treinamento, x_credit_teste), axis=0)\n",
    "y_credit = np.concatenate((y_credit_treinamento, y_credit_teste), axis=0)\n",
    "print(x_credit.shape)\n",
    "print(x_credit.shape)\n",
    "parameters = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'C': [1.0, 1.5, 2.0],\n",
    "              'tol': [1e-3, 1e-4, 1e-5]}\n",
    "grid_search = GridSearchCV(estimator=SVC(), param_grid=parameters)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(best_parameters)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1.5, kernel = 'rbf', tol = 0.001\n"
     ]
    }
   ],
   "source": [
    "def prepare_tree_parameters(parameters):\n",
    "    equal_or_comma = ','\n",
    "    converted_parameters = ''\n",
    "    for i in range(len(parameters)):\n",
    "        if equal_or_comma == ',':\n",
    "            if parameters[i] == \"'\":\n",
    "                converted_parameters += ''\n",
    "            elif parameters[i] == \":\":\n",
    "                converted_parameters += ' ='\n",
    "                equal_or_comma = '='\n",
    "            else:\n",
    "                converted_parameters += parameters[i]\n",
    "        elif equal_or_comma == '=': \n",
    "            if parameters[i] == \"'\":\n",
    "                converted_parameters += parameters[i]\n",
    "            elif parameters[i] == \",\":\n",
    "                converted_parameters += ','\n",
    "                equal_or_comma = ','\n",
    "            else:\n",
    "                converted_parameters += parameters[i]\n",
    "                \n",
    "            \n",
    "    return converted_parameters\n",
    "\n",
    "parameters = prepare_tree_parameters(\"'C': 1.5, 'kernel': 'rbf', 'tol': 0.001\")\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "results = []\n",
    "\n",
    "for i in range(30): \n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    tool = SVC(C = 1.5, kernel = 'rbf', tol = 0.001)\n",
    "    scores = cross_val_score(tool, x_credit, y_credit, cv = kfold)\n",
    "    # print(scores)\n",
    "    results.append(scores.mean())\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50f9dc88fbf78228e28ca27dec02a2c0a62082556f09da821a5db223c4e74185"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
